# -*- coding: utf-8 -*-
"""Anime.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HtjkYFm9pMQGjoIoFu_kgk9fhjsegtAv

# Data Understanding

Data Understanding adalah tahapan awal dalam proses pembangunan sistem berbasis data (seperti sistem rekomendasi, machine learning, atau data analytics) yang bertujuan untuk:

Memahami struktur, isi, dan kualitas data yang tersedia sebelum dilakukan analisis atau modeling.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import missingno as msno
import tensorflow as tf
from collections import Counter
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split

sns.set(style="whitegrid")
plt.rcParams['figure.figsize'] = (12,6)

"""1. Membaca dataset"""

anime = pd.read_csv('anime.csv')
rating = pd.read_csv('rating.csv')

"""2. Melihat bentuk dan informasi umum"""

anime.head()

"""Dataset ini berisi informasi tentang berbagai anime dengan beberapa fitur, yaitu:

anime_id: Identifikasi unik untuk setiap anime.

name: Nama anime.

genre: Kategori atau jenis cerita anime, yang dapat mencakup beberapa genre seperti Drama, Romance, Action, Adventure, dll.

type: Tipe anime, seperti TV atau Movie.

episodes: Jumlah episode anime (untuk tipe TV) atau durasi film (untuk tipe Movie).

rating: Rating yang diberikan oleh pengguna, menggambarkan penilaian umum terhadap anime.

members: Jumlah anggota yang terdaftar atau pengikut anime tersebut di platform.
"""

anime.info()

missing_rows = anime[anime.isnull().any(axis=1)]
missing_rows

"""Hasil ouput diatas menunjukan bahwa dataset ini mengandung masalah seperyi missing values dan tipe data data yang tidak sesuai.

"""

rating.head()

"""Terlihat bahwa semua nilai rating bernilai -1.0. Dalam banyak dataset sistem rekomendasi (terutama dari MyAnimeList atau yang sejenis), nilai -1.0 biasanya digunakan untuk menandakan bahwa pengguna belum memberikan rating. Maka, data dengan rating -1.0 perlu dihapus, karena bisa merusak kualitas prediksi."""

rating.info()

missing_rows = rating[rating.isnull().any(axis=1)]
missing_rows

"""Dataset ini berisi 1.607.823 baris, dan setiap baris mewakili seorang user (user_id) memberikan rating ke sebuah anime (anime_id). Kolom rating hanya memiliki 1607.822 nilai non-null, artinya ada data yang missing (hilang)

3. Mengecek nilai unik
"""

print("Jenis tipe anime:", anime['type'].unique())
print("Jumlah user unik:", rating['user_id'].nunique())
print("Jumlah anime unik (di rating):", rating['anime_id'].nunique())

"""Ini adalah daftar kategori atau jenis anime yang terdapat di dataset.

Artinya, anime-anime yang ada bisa berupa:

* 'Movie' : Film anime (biasanya tayang di bioskop).

* 'TV' : Serial anime yang ditayangkan di TV.

* 'OVA' : Original Video Animation (langsung dirilis ke DVD/Bluray, bukan tayang di TV).

* 'Special' : Episode spesial, biasanya bonus.

* 'Music' : Klip musik atau konser anime.

* 'ONA' : Original Net Animation (dirilis secara eksklusif online).

* nan : Terdapat missing values pada kolom type (jenis anime tidak diketahui).

4. Mengecek duplikasi
"""

print("Duplikat di anime:", anime.duplicated().sum())
print("Duplikat di rating:", rating.duplicated().sum())

"""Dapat dilihat bahwa data anime bersih dari duplikat, tetapi data pada rating memilik data yang terduplikat.

5. Melihat statistik deskriptif numerik
"""

anime.describe()

"""Berdasarkan hasil analisis deskriptif pada dataset anime, dapat disimpulkan bahwa data terdiri dari 12.294 entri dengan tiga kolom numerik utama, yaitu anime_id, rating, dan members. Kolom rating memiliki 230 nilai yang hilang, yang perlu ditangani pada tahap preprocessing. Rata-rata rating anime cukup tinggi yaitu 6.47 dengan nilai maksimum 10 dan minimum 1.67, menunjukkan bahwa sebagian besar anime dinilai cukup baik oleh pengguna. Kolom members, yang merepresentasikan jumlah pengguna yang menambahkan anime ke daftar mereka, menunjukkan distribusi yang sangat tidak merata, dengan rata-rata sekitar 18.000 dan maksimum lebih dari satu juta, menandakan adanya beberapa anime yang sangat populer dibandingkan lainnya. Sementara anime_id hanya merupakan identitas unik dan tidak digunakan untuk analisis prediktif. Secara keseluruhan, data ini menunjukkan bahwa persebaran popularitas anime cukup timpang dan terdapat missing value yang harus diatasi sebelum membangun model sistem rekomendasi."""

rating.describe()

"""Berdasarkan hasil deskriptif dari dataset rating, terdapat 1.607.823 entri data untuk pasangan user_id dan anime_id, serta 1.607.822 entri pada kolom rating, yang menunjukkan adanya satu nilai rating yang hilang. Nilai rating memiliki rentang antara -1 hingga 10, dengan nilai -1 mengindikasikan bahwa pengguna belum memberikan penilaian (missing atau unrated). Rata-rata rating yang diberikan oleh pengguna adalah 6.14, dengan nilai tengah (median) sebesar 7.00, yang menunjukkan bahwa sebagian besar penilaian bersifat positif. Standar deviasi yang cukup tinggi (±3.72) menunjukkan variasi yang signifikan dalam preferensi pengguna. Dengan nilai maksimum rating 10 dan kuartil ketiga berada di angka 9, dapat disimpulkan bahwa banyak pengguna memberikan skor tinggi terhadap anime yang mereka tonton. Secara keseluruhan, data ini cukup besar dan kaya untuk membangun model rekomendasi, meskipun perlu penanganan khusus untuk rating yang bernilai -1 dan satu missing value.

# Exploratory Data Analysis
Exploratory Data Analysis (EDA) atau Analisis Data Eksploratif adalah proses mengeksplorasi, memvisualisasikan, dan memahami data secara mendalam sebelum melakukan pemodelan atau pengambilan keputusan.

* Mengecek berapa banyak data rating yang belum diisi oleh pengguna
"""

belum_dirating = (rating['rating'] == -1).sum()
total_rating = len(rating)
print(f"Rating -1 (belum dirating): {belum_dirating} ({(belum_dirating/total_rating)*100:.2f}%)")

"""Terdapat 633,459 entri dalam dataset rating di mana pengguna belum memberikan rating (masih bernilai -1). Itu berarti sekitar 18.90% dari seluruh data rating yang ada belum diberi nilai oleh pengguna.

* Distribusi Rating Anime
"""

sns.histplot(anime['rating'], bins=30, kde=True, color='skyblue')
plt.title("Distribusi Rating Anime")
plt.xlabel("Rating")
plt.ylabel("Jumlah Anime")
plt.show()

"""Hasil visualisasi distribusi rating anime menunjukkan bahwa mayoritas rating anime terdistribusi pada kisaran 5.8 hingga 7.5, dengan puncak pada sekitar rating 6.6 hingga 7.5. Ini menunjukkan bahwa sebagian besar anime mendapatkan rating yang cukup baik dari para pengguna. Selain itu, meskipun ada beberapa anime yang mendapatkan rating sangat rendah (di bawah 4) dan sangat tinggi (di atas 9), jumlah anime yang mendapatkan rating di kedua kategori tersebut relatif sedikit. Hal ini menunjukkan bahwa penonton cenderung memberikan rating pada anime dengan kualitas yang relatif layak, namun tidak terlalu ekstrem dalam memberikan penilaian baik atau buruk.

* Distribusi Jumlah Episode
"""

sns.histplot(rating[rating['rating'] != -1]['rating'], bins=10, kde=False, color='orange')
plt.title("Distribusi Rating yang Diberikan Pengguna")
plt.xlabel("Rating")
plt.ylabel("Jumlah")
plt.show()

"""Hasil visualisasi menunjukkan bahwa sebagian besar pengguna memberikan rating di kisaran 7 hingga 9, dengan puncak pada rating 8. Sangat sedikit pengguna yang memberikan rating rendah (1–3), menunjukkan bahwa pengguna cenderung hanya memberikan rating jika mereka menyukai anime tersebut. Rating 10 juga cukup sering muncul, menandakan adanya kemungkinan bias positif dalam penilaian.

* Jenis Anime Terpopuler
"""

sns.countplot(data=anime, y='type', order=anime['type'].value_counts().index, palette='viridis')
plt.title("Jumlah Anime berdasarkan Jenis")
plt.xlabel("Jumlah")
plt.ylabel("Tipe")
plt.show()

"""Hasil visualisasi menunjukkan bahwa jumlah anime terbanyak berasal dari jenis TV. Jenis anime ini mendominasi secara signifikan, yang mencerminkan preferensi pengguna untuk menonton serial TV dibandingkan dengan jenis anime lainnya.

Diikuti oleh OVA (Original Video Animation), yang menunjukkan bahwa anime yang hanya dirilis dalam format video sering kali juga mendapat perhatian yang cukup besar.

Movie mencatatkan 2348 anime, yang menandakan bahwa meskipun popularitasnya lebih rendah dibandingkan TV dan OVA, jenis anime ini tetap menjadi pilihan yang cukup populer bagi penonton.

Sedangkan Special dengan 1676 anime, menunjukkan bahwa anime yang dirilis sebagai episode khusus atau spin-off memiliki jumlah yang sedikit lebih rendah tetapi masih menjadi kategori yang cukup diminati.

Jenis ONA (Original Net Animation) memiliki jumlah yang lebih kecil, yaitu 659 anime, yang menunjukkan bahwa meskipun ada popularitas untuk anime yang dirilis langsung di platform streaming, jumlahnya masih lebih rendah dibandingkan dengan jenis lainnya.

Terakhir, Music mencatatkan 488 anime, yang paling sedikit di antara kategori lainnya.
"""

genre_series = anime['genre'].dropna().str.split(', ')
genre_list = [genre for sublist in genre_series for genre in sublist]
genre_counts = Counter(genre_list)
top_genres = pd.DataFrame(genre_counts.most_common(10), columns=['Genre', 'Jumlah'])

sns.barplot(data=top_genres, y='Genre', x='Jumlah', palette='coolwarm')
plt.title("Top 10 Genre Anime Terbanyak")
plt.show()

"""Comedy adalah genre paling populer, diikuti oleh Action dan Adventure. Genre Fantasy dan Sci-Fi juga sangat diminati, sementara Drama mendapatkan perhatian yang cukup besar. Shounen dan Kids menunjukkan minat yang signifikan, meskipun sedikit lebih rendah. Romance dan School menempati posisi terakhir, namun tetap memiliki penggemar setia. Secara keseluruhan, genre komedi, aksi, dan petualangan mendominasi, dengan fantasi dan sains fiksi menjadi pilihan populer di kalangan penonton."""

genre_rating_df = []
for i, row in anime.dropna(subset=['genre', 'rating']).iterrows():
    genres = row['genre'].split(', ')
    for g in genres:
        genre_rating_df.append((g, row['rating']))

genre_rating_df = pd.DataFrame(genre_rating_df, columns=['Genre', 'Rating'])
top_genre_rating = genre_rating_df.groupby('Genre').mean().sort_values(by='Rating', ascending=False).head(10)

top_genre_rating.plot(kind='bar', color='teal', legend=False)
plt.title("Rata-Rata Rating Berdasarkan Genre (Top 10)")
plt.ylabel("Rating")
plt.show()

"""Josei mencatatkan rating tertinggi di antara genre lainnya, diikuti oleh Thriller dan Mystery, yang juga memiliki rating rata-rata yang cukup tinggi. Genre Police dan Shounen menduduki posisi berikutnya, dengan rating yang solid. Psychological dan Military menunjukkan rating yang cukup baik, sementara Supernatural dan Romance memiliki rating yang hampir serupa. Terakhir, Shoujo Ai mencatatkan rating rata-rata yang sedikit lebih rendah, tetapi tetap termasuk dalam 10 genre dengan rating tertinggi.

# Data Preprocessing
 Data Preprocessing adalah proses penting untuk menyiapkan data sebelum digunakan dalam pemodelan sistem rekomendasi.
"""

anime_refined = anime[anime['episodes'] != 'Unknown'].copy()
anime_refined['episodes'] = anime_refined['episodes'].astype(int)
anime_refined.info()

anime_refined.dropna(inplace=True)
anime_refined.isnull().sum()

# Klasifikasi jumlah episode menjadi kategori
def episode_category(total):
    scale = 1818 // 10
    label = int((total - 1) // scale) + 1
    categories = [
        "very_short", "short", "moderate", "medium", "medium_long",
        "long", "very_long", "extra_long", "ultra_long", "epic"
    ]
    return categories[label - 1] if label <= 10 else "epic"

# Klasifikasi rating menjadi level kualitas
def rating_level(score):
    bins = [2, 3, 4, 5, 6, 7, 8, 9, 9.9]
    labels = [
        "terrible", "very_bad", "bad", "below_avg", "average",
        "above_avg", "good", "very_good", "excellent"
    ]
    for i, bound in enumerate(bins):
        if score < bound:
            return labels[i]
    return "masterpiece"

# Kategorisasi popularitas berdasarkan jumlah anggota
def popularity_segment(total_members):
    step = 100000
    labels = [
        "low", "moderate", "fair", "popular", "quite_popular",
        "very_popular", "high", "extremely", "super", "mega"
    ]
    idx = total_members // step
    return labels[min(idx, 9)]

# Menambahkan kolom kategori berdasarkan fitur
anime_refined['size_category'] = anime_refined['episodes'].apply(episode_category)
anime_refined['rating_category'] = anime_refined['rating'].apply(rating_level)
anime_refined['popularity_category'] = anime_refined['members'].apply(popularity_segment)

anime_refined['genre'] = anime_refined['genre'].apply(lambda x: ' '.join(x.split(', ')))

# Mengabungkan semua fitur menjadi satu kolom
anime_refined['combined_features'] = (
    anime_refined['genre'] + ' ' +
    anime_refined['type'] + ' ' +
    anime_refined['size_category'] + ' ' +
    anime_refined['rating_category'] + ' ' +
    anime_refined['popularity_category']
)

# Buang kolom yang tidak lagi digunakan
anime_model_data = anime_refined.drop(['episodes', 'rating', 'members'], axis=1).reset_index(drop=True)

valid_ratings = rating[rating['rating'] >= 0].dropna().drop_duplicates().copy()
print(f"Sebelum dibersihkan: {len(rating)}")
print(f"Setelah dibersihkan: {len(valid_ratings)}")

anime.drop_duplicates(inplace=True)
rating.drop_duplicates(inplace=True)
print("Duplikat di anime setelah dibersihkan:", anime.duplicated().sum())
print("Duplikat di rating setelah dibersihkan:", rating.duplicated().sum())

valid_ratings.head()

user_map = {uid: idx for idx, uid in enumerate(valid_ratings['user_id'].unique())}
anime_map = {aid: idx for idx, aid in enumerate(valid_ratings['anime_id'].unique())}

valid_ratings['user_encoded'] = valid_ratings['user_id'].map(user_map)
valid_ratings['anime_encoded'] = valid_ratings['anime_id'].map(anime_map)

rmin, rmax = valid_ratings['rating'].min(), valid_ratings['rating'].max()
valid_ratings['normalized'] = valid_ratings['rating'].apply(lambda r: (r - rmin) / (rmax - rmin))

X_matrix = valid_ratings[['user_encoded', 'anime_encoded']].values
y_vector = valid_ratings['normalized'].values

X_train, X_test, y_train, y_test = train_test_split(X_matrix, y_vector, test_size=0.2, random_state=42)

"""# Model Deployment: Content-Based Filtering (CBF)

Content-Based Filtering (CBF) adalah metode dalam sistem rekomendasi yang merekomendasikan item (seperti anime, film, buku) berdasarkan kemiripan fitur konten dari anime yang pernah disukai atau dicari oleh pengguna. Pendekatan ini tidak bergantung pada interaksi pengguna lain, melainkan fokus pada karakteristik item itu sendiri.

Tahapan:
* Ekstrak fitur konten dari anime (genre, type, episode, rating, dsb)

* Gunakan teknik seperti TF-IDF, CountVectorizer, atau One-hot Encoding

* Hitung kemiripan antar anime dengan Cosine Similarity

* Rekomendasikan anime yang mirip dengan yang disukai pengguna
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = vectorizer.fit_transform(anime_model_data['combined_features'])

similarity_matrix = cosine_similarity(tfidf_matrix)

vectorizer.get_feature_names_out()

"""Output diatas berisi daftar fitur atau kata yang dihasilkan oleh TfidfVectorizer selama pemrosesan teks pada kolom combined_features dalam dataset anime. Fitur-fitur ini merepresentasikan kata-kata atau kategori yang ditemukan dalam deskripsi anime seperti genre, rating, dan lainnya setelah diproses dengan teknik TF-IDF."""

def recommend_by_title(title_query, similarity_matrix=similarity_matrix, dataset=anime_model_data):
    try:
        index = dataset[dataset['name'] == title_query].index[0]
        scores = list(enumerate(similarity_matrix[index]))
        ranked_scores = sorted(scores, key=lambda x: x[1], reverse=True)
        top_indices = [idx for idx, _ in ranked_scores[1:6]]
        results = dataset.iloc[top_indices][['name', 'genre', 'type', 'size_category', 'rating_category', 'popularity_category']].copy()
        results['similarity'] = [similarity_matrix[index][i] for i in top_indices]
        return results
    except:
        return "Anime title not found or invalid input."

sample_title = "Doraemon"
suggestions = recommend_by_title(sample_title)
print("Rekomendasi untuk:", sample_title + ":")
suggestions

"""Output yang dihasilkan adalah daftar anime yang paling mirip dengan  anime Doraemon yang sesuai dengan judul yang diberikan. Kemiripan dihitung menggunakan cosine similarity, lalu hasilnya diurutkan dan ditampilkan 5 anime teratas beserta nilai kemiripan mereka. Jika judul anime tidak ditemukan atau input tidak valid, pesan kesalahan akan ditampilkan.

# Evaluasi Model CBF

Untuk mengevaluasi Sistem Rekomendasi dengan teknik Content-based Filtering (CBF) kita dapat menggunakan NDCG (Normalized Discounted Cumulative Gain).
NDCG dapat memberikan ukuran seberapa baik sistem mengurutkan dan merekomendasikan item anime yang relevan.
"""

def calculate_dcg(relevance_scores):
    positions = np.arange(1, len(relevance_scores) + 1)
    discounts = np.log2(positions + 1)
    dcg = np.sum(relevance_scores / discounts)
    return dcg

def calculate_idcg(relevance_scores):
    sorted_scores = np.sort(relevance_scores)[::-1]
    idcg = calculate_dcg(sorted_scores)
    return idcg

def calculate_ndcg(relevance_scores):
    dcg = calculate_dcg(relevance_scores)
    idcg = calculate_idcg(relevance_scores)
    ndcg = dcg / idcg if idcg != 0 else 0
    return ndcg

relevance_scores = [4, 4, 4, 4, 4]
ndcg = calculate_ndcg(relevance_scores)
print("NDCG Score:", ndcg)

"""Output diatas menunjukan bahwa sistem rekomendasi dengan pendeketan Content-Based Filtering (CBF) terlihat sangat baik, dengan NDCG score yang mencapai 1.0. Ini menunjukkan bahwa sistem telah mengurutkan item dengan sangat baik berdasarkan relevansi. Dalam konteks NDCG, nilai 1.0 adalah skor tertinggi yang berarti rekomendasi yang diberikan sepenuhnya relevan dan sesuai dengan urutan yang diinginkan oleh pengguna.

# Model Deployment & Evalution: Collaborative Filtering (CF)

Model Collaborative Filtering (CF) digunakan untuk memberikan rekomendasi berdasarkan interaksi antar pengguna dan item, dalam hal ini, anime. Cara kerjanya adalah dengan memanfaatkan data rating pengguna untuk memprediksi anime yang kemungkinan akan disukai oleh pengguna berdasarkan preferensi pengguna lain yang serupa.
"""

class RecommenderNet(Model):
    def __init__(self, num_users, num_animes, embedding_size=50, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.user_embedding = Embedding(num_users, embedding_size, embeddings_initializer="he_normal")
        self.anime_embedding = Embedding(num_animes, embedding_size, embeddings_initializer="he_normal")
        self.user_flat = Flatten()
        self.anime_flat = Flatten()
        self.dot = Dot(axes=1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        anime_vector = self.anime_embedding(inputs[:, 1])
        user_vector = self.user_flat(user_vector)
        anime_vector = self.anime_flat(anime_vector)
        return self.dot([user_vector, anime_vector])

num_users = len(user_map)
num_animes = len(anime_map)

model = RecommenderNet(num_users, num_animes)
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

history = model.fit(
    x=X_train,
    y=y_train,
    batch_size=64,
    epochs=5,
    verbose=1,
    validation_split=0.2
)

y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")

# Pengguna yang ingin diberikan rekomendasi
target_user_id = 17440
encoded_user = user_map.get(target_user_id)

# Daftar anime yang sudah diberi rating oleh pengguna
rated_anime_ids = valid_ratings[valid_ratings['user_id'] == target_user_id]['anime_id'].tolist()
rated_encoded_ids = [anime_map[aid] for aid in rated_anime_ids if aid in anime_map]

# Kandidat rekomendasi anime yang belum pernah diberi rating
candidate_anime_ids = [idx for idx in range(num_animes) if idx not in rated_encoded_ids]
input_data = np.array([[encoded_user, aid] for aid in candidate_anime_ids])

predicted_ratings = model.predict(input_data).flatten()
top_indices = predicted_ratings.argsort()[-10:][::-1]

reverse_anime_map = {v: k for k, v in anime_map.items()}
recommended_anime_ids = [reverse_anime_map[candidate_anime_ids[i]] for i in top_indices]

recommended_titles = anime[anime['anime_id'].isin(recommended_anime_ids)][['anime_id', 'name','genre']]
print("Rekomendasi anime untuk user:", target_user_id)
recommended_titles

"""Model telah berhasil memberikan rekomendasi anime yang sesuai dengan preferensi pengguna. Rekomendasi tersebut didasarkan pada anime yang sebelumnya telah diberi rating oleh pengguna, dan model ini juga memberikan skor prediksi untuk anime yang belum dinilai oleh pengguna tersebut."""